{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6903f6e",
   "metadata": {},
   "source": [
    "# Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90f7d4",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70c24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1174a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c15c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports.\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62be64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancillar_path: str = \"/llm_app/learning/build_large_language_models_from_scratch/\"\n",
    "\n",
    "if ancillar_path not in sys.path:\n",
    "    sys.path.append(ancillar_path)\n",
    "\n",
    "import ancillar as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c710064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.3\n",
      "matplotlib version: 3.10.0\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1+cpu\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",  # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",  # Tokenizer\n",
    "    \"torch\",  # Deep learning library\n",
    "    \"tqdm\",  # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f4658",
   "metadata": {},
   "source": [
    "## Preparing a Dataset for Supervised Instruction Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fd30ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = aux.download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8d0d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf930e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89aa3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = aux.format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cacfc996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = aux.format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10dcecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # Use 85% of the data for training.\n",
    "test_portion = int(len(data) * 0.1)  # Use 10% for testing.\n",
    "val_portion = (\n",
    "    len(data) - train_portion - test_portion\n",
    ")  # Use remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion : train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion :]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354cf3e",
   "metadata": {},
   "source": [
    "## Organizing Data into Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee979d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb15c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23ceb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "print(aux.custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4434cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = aux.custom_collate_draft_2(batch)\n",
    "\n",
    "print(inputs)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a8b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = aux.custom_collate_fn(batch)\n",
    "\n",
    "print(inputs)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0dbb087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor([\n",
    "    [-1.0, 1.0],\n",
    "    [-0.5, 1.5]\n",
    "])\n",
    "\n",
    "# Correct token indices to generate.\n",
    "targets_1 = torch.tensor([0, 1]) \n",
    "\n",
    "# Compute the loss.\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aa870ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor([\n",
    "    [-1.0, 1.0],\n",
    "    [-0.5, 1.5],\n",
    "    [-0.5, 1.5]\n",
    "])\n",
    "\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c71a9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4d6fa",
   "metadata": {},
   "source": [
    "## Creating Data Loaders for an Instruction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47ffd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU, MPS, or CPU.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "# Use MPS (Apple Silicon) if GPU is not available\n",
    "elif torch.backends.mps.is_available():\n",
    "    \n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a0b43e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show it\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39d04a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<function custom_collate_fn at 0x7f28241d7740>, device=device(type='cpu'), allowed_max_length=1024)\n"
     ]
    }
   ],
   "source": [
    "customized_collate_fn = partial(\n",
    "    aux.custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")\n",
    "\n",
    "print(customized_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34be4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to increase this number if parallel Python processes are\n",
    "# supported by your operating system.\n",
    "num_workers = 0\n",
    "\n",
    "# Batch size for data loaders.\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5c0e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = aux.InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06c5196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = aux.InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78963cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = aux.InstructionDataset(test_data, tokenizer)\n",
    "test_loader = aux.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe0fe131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n"
     ]
    }
   ],
   "source": [
    "for _ in range(9):\n",
    "\n",
    "    # Grab a single batch from the training data loader.\n",
    "    example_batch: Tuple[torch.Tensor, torch.Tensor] = next(iter(train_loader))\n",
    "\n",
    "    # Unpack the batch into inputs and targets.\n",
    "    inputs, targets = example_batch\n",
    "\n",
    "    # Show shapes\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e0eb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198, 22743,   262,  1708, 23491,  7457,    13,\n",
       "          198,   198, 21017, 23412,    25,   198,  2990,  3382,   284,   467,\n",
       "          284,   262,  6918,    11,   475,   484,   423,   645,  1637,    13,\n",
       "          198,   198, 21017, 18261,    25,   198,  2990,   765,   284,   467,\n",
       "          284,   262,  6918,    11,   475,   484,   423,   645,  1637,    13])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6590996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
       "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
       "        46486,    25,   198, 22743,   262,  1708, 23491,  7457,    13,   198,\n",
       "          198, 21017, 23412,    25,   198,  2990,  3382,   284,   467,   284,\n",
       "          262,  6918,    11,   475,   484,   423,   645,  1637,    13,   198,\n",
       "          198, 21017, 18261,    25,   198,  2990,   765,   284,   467,   284,\n",
       "          262,  6918,    11,   475,   484,   423,   645,  1637,    13, 50256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a277fd6",
   "metadata": {},
   "source": [
    "## Loading a Pretrained LLM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
